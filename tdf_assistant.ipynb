{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliyaAM/TDF_assistant/blob/main/tdf_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "5kY0r4RmnFzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d73ae8ee-02d7-4d00-9463-a1f2924132f6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.28.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7JndLTP_BNW",
        "outputId": "edb0b956-5676-4533-e38b-bce9ffef84bc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.29.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.129.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-httplib2) (0.22.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.63.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install openai"
      ],
      "metadata": {
        "id": "tq-VwLEfnJ3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fbc76aa-b441-4c3a-8173-044540f246cb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ openai@4.45.0\n",
            "updated 1 package and audited 39 packages in 1.055s\n",
            "\n",
            "1 package is looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://api.openai.com/v1/models -H \"Authorization: Bearer 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\" -H \"OpenAI-Organization: org-ra77WoriYLMPdDinDlSp0eFb\""
      ],
      "metadata": {
        "id": "zUH4VC3cnPJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "163eaa8a-31c8-4108-e82a-a79501a60ccd"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"list\",\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"id\": \"dall-e-3\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1698785189,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"whisper-1\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1677532384,\n",
            "      \"owned_by\": \"openai-internal\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"davinci-002\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1692634301,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"dall-e-2\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1698798177,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-16k\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1683758102,\n",
            "      \"owned_by\": \"openai-internal\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"tts-1-hd-1106\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1699053533,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"tts-1-hd\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1699046015,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-4\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1687882411,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-4-0613\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1686588896,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-1106\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1698959748,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-instruct-0914\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1694122472,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-instruct\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1692901427,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"tts-1\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1681940951,\n",
            "      \"owned_by\": \"openai-internal\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1677610602,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-0301\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1677649963,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-4-turbo-2024-04-09\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1712601677,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"babbage-002\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1692634615,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-4-1106-preview\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1698957206,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-4-0125-preview\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1706037612,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"tts-1-1106\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1699053241,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-0125\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1706048358,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-4-turbo-preview\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1706037777,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-embedding-3-large\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1705953180,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-embedding-3-small\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1705948997,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-0613\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1686587434,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-embedding-ada-002\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1671217299,\n",
            "      \"owned_by\": \"openai-internal\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-4-1106-vision-preview\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1711473033,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-4-turbo\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1712361441,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-4-vision-preview\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1698894917,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-16k-0613\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1685474247,\n",
            "      \"owned_by\": \"openai\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1wBFmnn5nPBw"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Sequence\n",
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "\n",
        "import openai\n",
        "\n",
        "import networkx as nx\n",
        "import textwrap\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "1ChJsbsonFw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38db3930-c2b9-4a78-e2e9-774cefe8dd3c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not delete these comments.\n",
        "\n",
        "# openai.organization = \"org-ra77WoriYLMPdDinDlSp0eFb\"\n",
        "# openai.api_key = \"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\"\n",
        "# openai.Model.list()"
      ],
      "metadata": {
        "id": "bbVAnms2te3T"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### in-context learning"
      ],
      "metadata": {
        "id": "vJ7gJ_1k0X3g"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "in-context learning"
      ],
      "metadata": {
        "id": "TCaTf5hN0iPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up colored printing\n",
        "\n",
        "class Color:\n",
        "   # The following is the allowed list of colors.\n",
        "   PURPLE = '\\033[1;35;48m'\n",
        "   CYAN = '\\033[1;36;48m'\n",
        "   BOLD = '\\033[1;37;48m'\n",
        "   BLUE = '\\033[1;34;48m'\n",
        "   GREEN = '\\033[1;32;48m'\n",
        "   YELLOW = '\\033[1;33;48m'\n",
        "   RED = '\\033[1;31;48m'\n",
        "   BLACK = '\\033[1;30;48m'\n",
        "   # You can choose to UNDERLINE text if you like.\n",
        "   UNDERLINE = '\\033[4;37;48m'\n",
        "   # END is used internally, you can ignore it.\n",
        "   END = '\\033[1;37;0m'\n",
        "\n",
        "\n",
        "def colored(text: str, color: str):\n",
        "  color_code = Color.__getattribute__(Color, color)\n",
        "  end_code = Color.__getattribute__(Color, 'END')\n",
        "  return color_code + text + end_code\n",
        "\n",
        "# Test that it works.\n",
        "print(colored('This should print in blue. ', 'BLUE') +\n",
        "      colored('This should print in yellow. ', 'YELLOW') +\n",
        "     'this should print in the default color.')"
      ],
      "metadata": {
        "id": "0MHL2sXqn9ti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804c7f85-e6eb-4b22-bd9f-16c34d8e8c94"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;34;48mThis should print in blue. \u001b[1;37;0m\u001b[1;33;48mThis should print in yellow. \u001b[1;37;0mthis should print in the default color.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=\"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\",\n",
        ")"
      ],
      "metadata": {
        "id": "UE8f6h4JIGfZ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tdf_explanation = (\n",
        "    \"The theoretical domains framework (TDF) is a framework for \"\n",
        "    \"qualitative analysis. \"\n",
        "    \"The Theoretical Domains Framework (TDF) \"\n",
        "    \"was developed by a collaboration of behavioural scientists and \"\n",
        "    \"implementation researchers who identified theories relevant to \"\n",
        "    \"implementation and grouped constructs from \"\n",
        "    \"these theories into domains. \"\n",
        "    \"The collaboration aimed to provide a comprehensive, \"\n",
        "    \"theory-informed approach to identify determinants of behaviour. \"\n",
        "    \"A domain is \"\n",
        "    \"Explain barriers and enablers \"\n",
        "    \"You are a health psychologist who specialises \"\n",
        "    \"in qualitative research methods. \"\n",
        "    \"As your main day-to-day job, \"\n",
        "    \"you annotate paragraphs of transcribed verbatim interviews. \"\n",
        "    \"You line-by-line annotate quotes within each paragraph using TDF. \"\n",
        "    \"This involves reading the paragraph and categorizing the quotes into \"\n",
        "    \"14 TDF domains. \"\n",
        "    \"The 14 domains are \"\n",
        "    \"1) Knowledge; \"\n",
        "    \"2) Skills; \"\n",
        "    \"3) Social/professional role and identity; \"\n",
        "    \"4) Beliefs about capabilities; \"\n",
        "    \"5) Optimism; \"\n",
        "    \"6) Beliefs about consequences; \"\n",
        "    \"7) Reinforcement; \"\n",
        "    \"8) Intentions; \"\n",
        "    \"9) Goals; \"\n",
        "    \"10) Memory, attention, and decision processes; \"\n",
        "    \"11) Environment context and resources; \"\n",
        "    \"12) Social influences; \"\n",
        "    \"13) Emotion; \"\n",
        "    \"14) Behavioral regulation. \"\n",
        "    \"It is OK if there is more than one domain in one paragraph. \"\n",
        "    \"Show your work. Print the text from the paragraph (i.e., quote) \"\n",
        "    \"that you used to identify each domain. \"\n",
        "    \"For each identified domain, \"\n",
        "    \"include the quote from the paragraph that \"\n",
        "    \"maps onto the domain. \"\n",
        "    \"Always print the exact quote from the paragraph and encapsulate it in quotation marks. \"\n",
        "    \"At the end, print out a table summarising the explanation only, \"\n",
        "    \"where the first column is the domain name and \"\n",
        "    \"the second column is the quote \"\n",
        "    \"group the table by domains in the following order: \"\n",
        "    \"1) Knowledge; \"\n",
        "    \"2) Skills; \"\n",
        "    \"3) Social/professional role and identity; \"\n",
        "    \"4) Beliefs about capabilities; \"\n",
        "    \"5) Optimism; \"\n",
        "    \"6) Beliefs about consequences; \"\n",
        "    \"7) Reinforcement; \"\n",
        "    \"8) Intentions; \"\n",
        "    \"9) Goals; \"\n",
        "    \"10) Memory, attention, and decision processes; \"\n",
        "    \"11) Environment context and resources; \"\n",
        "    \"12) Social influences; \"\n",
        "    \"13) Emotion; \"\n",
        "    \"14) Behavioral regulation. \"\n",
        "    \"add a third column counting the number of quotes for each domain \"\n",
        "    \"Here are some examples of how to apply TDF to \"\n",
        "    \"extract the domains from a paragraph about barriers and enablers \"\n",
        "    \"influencing health professional's behaviour, such as implementation of \"\n",
        "    \"best practices and medical guidelines: \"\n",
        ")"
      ],
      "metadata": {
        "id": "gfs_CzFpIzzQ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = []\n",
        "\n",
        "# 1) Knowledge\n",
        "examples.append((\n",
        "    'Quote: \"you educate the patients on you know, '\n",
        "    'safety awareness between hot cold \\n'\n",
        "    'and sharp objects and what not, '\n",
        "    'but in terms of rehabilitation...I\\'m just not aware of what to do.\"\\n'\n",
        "    'Domain: \"Knowledge\" '\n",
        "    ))\n",
        "\n",
        "# 2) Skills\n",
        "examples.append((\n",
        "    'Quote: \"I think a lot of it is to do with the training, '\n",
        "    'I was talking to a few junior doctors in respiratory \\n'\n",
        "    'and a lot of them haven\\'t even heard about the training '\n",
        "    'package on the website, but they’re putting tubes down.\" \\n'\n",
        "    'Domain: \"Skills\" '\n",
        "    ))\n",
        "\n",
        "# 3) Social/professional role and identity\n",
        "examples.append((\n",
        "    'Quote:\"A sense that I was not a medical professional, '\n",
        "    'and this might be out of my realm of service.\" '\n",
        "    'Domain: \"Social/professional role and identity\" '\n",
        "    ))\n",
        "\n",
        "# 4) Beliefs about capabilities\n",
        "examples.append((\n",
        "    'Quote: \"I think there might also be an issue with confidence.\" '\n",
        "    'Domain: \"Beliefs about capabilities\" '\n",
        "    ))\n",
        "\n",
        "# 5) Optimism\n",
        "examples.append((\n",
        "    'Quote: \"I feel a mix of excitement and scepticism, to be honest.\" '\n",
        "    'Domain: \"Optimism\" '\n",
        "    ))\n",
        "\n",
        "# 6) Beliefs about consequences\n",
        "examples.append((\n",
        "    'Quote: \"Because my credibility, you know,if I start saying, '\n",
        "    'you know, smoking increases your risk of lung cancer \\n'\n",
        "    'or doing this does that, '\n",
        "    'and I’m standing there as a skin cancer specialist nurse, \\n'\n",
        "    'I think that you, it all just turns into a bit of a blah blah blah\" \\n'\n",
        "    'Domain: \"Beliefs about consequences\" '\n",
        "    ))\n",
        "\n",
        "# 7) Reinforcement\n",
        "examples.append((\n",
        "    'Quote: \"I think everyone\\’s very happy to do things '\n",
        "    'if they feel the patient is going to get a better outcome from it, '\n",
        "    'and I think that’s one of the biggest drivers for our inpatient\" '\n",
        "    'Domain: \"Reinforcement\" '\n",
        "    ))\n",
        "\n",
        "# 8) Intentions\n",
        "examples.append((\n",
        "    'Quote: \"I\\’m keen to apply it more broadly I guess,'\n",
        "    'across the board rather than just the ones that are really severe.\" '\n",
        "    'Domain: \"Intentions\" '\n",
        "    ))\n",
        "\n",
        "# 9) Goals\n",
        "examples.append((\n",
        "    'Quote: \"there\\’s so many other things we need to look at like home '\n",
        "    'assess and other functions and mobility, so yeah, '\n",
        "    'it’s a bit low on the priority list\" '\n",
        "    'Domain: \"Goals\" '\n",
        "    ))\n",
        "\n",
        "# 10) Memory, attention, and decision processes\n",
        "examples.append((\n",
        "    'Quote: \"\"When you\\re doing risk assessments, '\n",
        "    'just those few seconds away where you\\'re '\n",
        "    'looking at the computer or typing, you miss '\n",
        "    'moments with the patient where they might open up '\n",
        "    'or you just miss the odd little slip in their body '\n",
        "    'language that might help you.\" '\n",
        "    'Domain: \"Memory, attention, and decision processes\" '\n",
        "    ))\n",
        "\n",
        "# 11) Environment context and resources\n",
        "examples.append((\n",
        "    'Quote: \"I think time constraints from an inpatientpoint of view because '\n",
        "    'every one is so stretched, and I think '\n",
        "    'even with some of my [musculoskeletal] colleagues \\n'\n",
        "    'they feel that they have to just treat what\\'s in front of them '\n",
        "    'in the time that they have.\" \\n'\n",
        "    'Domain: \"Environmental contextand resources\"'\n",
        "    ))\n",
        "\n",
        "# 12) Social influences\n",
        "examples.append((\n",
        "    'Quote: \"If my boss told me to do one it would \\n'\n",
        "    'be very difficult for me to, '\n",
        "    'depending on which the boss was, generally you\\'d be like no \\n'\n",
        "    'but don\\'t you know that local guidelines are…they’d be like '\n",
        "    'I said get a chest x-ray, you\\'d be like oh alright.\" \\n'\n",
        "    'Domain: \"Social influences\"'\n",
        "    ))\n",
        "\n",
        "# 13) Emotion\n",
        "examples.append((\n",
        "    'Quote: \"I think the nurses are still quite anxious because it\\'s so big '\n",
        "    'even now I think they\\'re still anxious about pH and they just want to \\n'\n",
        "    'know that it\\'s in the right place.\" \\n'\n",
        "    'Domain: \"Emotion\" '\n",
        "    ))\n",
        "\n",
        "# 14) Behavioral regulation.\n",
        "examples.append((\n",
        "    'Quote: \"I did some reading upon this immediately and \\n'\n",
        "    'then in grained in my mind what were '\n",
        "    'the exact differences I was doing some reading up and \\n'\n",
        "    'became aware of the study,becauseI felt that was a gap in my knowledge. \\n'\n",
        "    'Obviously, I was offering all the antenatal screening, apart from the \\n'\n",
        "    'genetic carrier screening which is now something that I do \\n'\n",
        "    'mention to couples.\" \\n'\n",
        "    'Domain: \"Behaviour regulation\" '\n",
        "    ))\n",
        "\n",
        "\n",
        "examples.append((\n",
        "    'Quote: \"The main barriers I face in being physically active are '\n",
        "    'my health conditions, '\n",
        "    'including heart failure, aortic stenosis, pulmonary hypertension, diabetes, '\n",
        "    'and rheumatoid arthritis. These conditions limit my physical abilities and  '\n",
        "    'energy levels and make it difficult for me to do more physical activity./n '\n",
        "    'Additionally, living in a rural area with limited infrastructure '\n",
        "    'and options for physical activity can be a barrier as well. '\n",
        "    'Other barriers include my sedentary lifestyle, '\n",
        "    'which can make it hard to break the habit of being inactive, '\n",
        "    'and external factors such as weather, '\n",
        "    'which can make it difficult to go outside and be active. '\n",
        "    'My schedule and other commitments can also be a barrier, '\n",
        "    'making it hard to find the time to be active. '\n",
        "    'On the other hand, enablers that help me '\n",
        "    'to be more physically active include setting small, '\n",
        "    'achievable goals for myself, finding activities that I enjoy, '\n",
        "    'having a companion to exercise with, '\n",
        "    'and listening to my body and being mindful of my health conditions. '\n",
        "    'My home environment also can help as it is equipped with safety features '\n",
        "    'that make it easier for me to move around. '\n",
        "    'The advice and guidelines from my healthcare providers '\n",
        "    'also help me to stay active in a safe way. '\n",
        "    'Domain: \"Beliefs about capabilities\", '\n",
        "    '\"Environmental context and resources\", '\n",
        "    '\"Goals\", '\n",
        "    '\"Behavioural regulation\", '\n",
        "    '\"Social influences\", '\n",
        "\n",
        "    'Explanation:'\n",
        "    '\"Beliefs about capabilities\" is noted because of the following quote: '\n",
        "    '\"The main barriers I face in '\n",
        "    'being physically active are my health conditions, '\n",
        "    'including heart failure, '\n",
        "    'aortic stenosis, pulmonary hypertension, diabetes, '\n",
        "    'and rheumatoid arthritis. '\n",
        "    'These conditions limit my physical abilities and '\n",
        "    'energy levels and make it difficult for me to do more '\n",
        "    'physical activity.\"/n '\n",
        "    '\"Environmental context and resources\" '\n",
        "    'is noted because of the following quote: '\n",
        "    '\"Additionally, living in a rural area with limited infrastructure '\n",
        "    'and options for physical activity can be a barrier as well./n '\n",
        "    '\"Environmental context and resources\" '\n",
        "    'is noted because of the following quote: '\n",
        "    '\"and external factors such as weather, which can make it '\n",
        "    'difficult to go outside and be active.\" /n'\n",
        "    '\"Goals\" is noted because of the following quote: '\n",
        "    '\"On the other hand, enablers that help me to be more physically '\n",
        "    'active include setting small, achievable goals for myself,\" /n'\n",
        "    '\"Behavioural regulation\" '\n",
        "    'is noted because of the following quote: '\n",
        "    '\"finding activities that I enjoy,\" /n'\n",
        "    '\"Social influences\" '\n",
        "    'is noted because of the following quote: '\n",
        "    '\"having a companion to exercise with,\" '\n",
        "    '\"Environmental context and resources\" '\n",
        "    'is noted because of the following quote: '\n",
        "    '\"My home environment also can help as '\n",
        "    'it is equipped with safety features '\n",
        "    'that make it easier for me to move around.\" /n'\n",
        "    '\"Social influences\" '\n",
        "    'is noted because of the following quote: '\n",
        "    '\"The advice and guidelines from my healthcare providers '\n",
        "    'also help me to stay active in a safe way.\" /n'\n",
        "  ))\n",
        "\n",
        "examples_str = '\\n'.join(examples)\n"
      ],
      "metadata": {
        "id": "LBTfiOhpfLlt"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Form full instructions by concatenating tdf_explanation with examples.\n",
        "instructions = tdf_explanation + '\\n' + examples_str"
      ],
      "metadata": {
        "id": "ZKWA3m5bfy2I"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define the sampler function\n",
        "\n",
        "MAX_TRIES = 100\n",
        "\n",
        "def sampler(content: str) -> str:\n",
        "  \"\"\"Create an assistant, sample it once, get its reply, and then delete it.\"\"\"\n",
        "  assistant = client.beta.assistants.create(\n",
        "      name=\"Theoretical Domains Framework Assistant\",\n",
        "      # JZL: Apparently the last instructions you pass override earlier ones. So\n",
        "      # the run instructions we pass later will override the instructions we\n",
        "      # pass on creation of the assistant here. See:\n",
        "      # https://community.openai.com/t/assistant-vs-thread-instructions/517920\n",
        "      instructions='',\n",
        "      # tools=[{\"type\": \"code_interpreter\"}],\n",
        "      model=\"gpt-4-turbo\",\n",
        "  )\n",
        "\n",
        "  thread = client.beta.threads.create()\n",
        "  message = client.beta.threads.messages.create(\n",
        "      thread_id=thread.id,\n",
        "      role=\"user\",\n",
        "      content=content + '\\nPlease respond in plain text.',\n",
        "  )\n",
        "\n",
        "  run = client.beta.threads.runs.create(\n",
        "      thread_id=thread.id,\n",
        "      assistant_id=assistant.id,\n",
        "      instructions=instructions,\n",
        "  )\n",
        "\n",
        "  print(\"checking whether assistant has finished processing..\")\n",
        "  num_tries_so_far = 0\n",
        "  while True:  # This will create an infinite loop if openai never responds.\n",
        "    num_tries_so_far += 1\n",
        "    if num_tries_so_far == MAX_TRIES:\n",
        "      raise ValueError(f'OpenAI did not respond after {MAX_TRIES} attempts.')\n",
        "\n",
        "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "    if run.status == \"completed\":\n",
        "      print(\"done!\")\n",
        "      messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "      for message in messages:\n",
        "        assert message.content[0].type == \"text\"\n",
        "        if message.role == 'assistant':\n",
        "          print(message.content[0].text.value)\n",
        "          return message.content[0].text.value\n",
        "      client.beta.assistants.delete(assistant.id)\n",
        "      break\n",
        "    else:\n",
        "      print(\"in progress...\", run.status, run.model, run.last_error)\n",
        "      time.sleep(5)\n",
        "\n",
        "  return ''"
      ],
      "metadata": {
        "id": "LUIowyPXiWKk"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler(\"hello Chatgpt, are you there?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky9ybMjNZq0r",
        "outputId": "98f6bf01-d3f3-4f14-87f2-b7230d437b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checking whether assistant has finished processing..\n",
            "in progress... queued gpt-4-turbo None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_formatting(text):\n",
        "  # This pattern matches ANSI escape sequences\n",
        "  ansi_escape_pattern = re.compile(r'\\x1b\\[[0-9;]*m')\n",
        "  # Use sub() method to replace the matched patterns with an empty string\n",
        "  clean_text = re.sub(ansi_escape_pattern, '', text)\n",
        "  return clean_text"
      ],
      "metadata": {
        "id": "8GShYy5cykrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_coloring(text: str):\n",
        "    indices = text.find('\"')\n",
        "    output = ''\n",
        "    prev_idx = 0\n",
        "    idx = 0\n",
        "    z = 0\n",
        "    while idx >= 0:\n",
        "      color = 'BLUE'\n",
        "      if z % 2 == 0:\n",
        "        color = 'RED'\n",
        "\n",
        "      idx = text.find('\"', prev_idx, -1)\n",
        "      output += colored(text[prev_idx: idx], color=color)\n",
        "\n",
        "      prev_idx = idx + 1\n",
        "      z += 1\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "_VDex8cLqLtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prevent_unicode_problems(text: str) -> str:\n",
        "    return text.encode('ascii', 'namereplace').decode()"
      ],
      "metadata": {
        "id": "Q8P6IZJZtD9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define the get_domain function.\n",
        "\n",
        "def get_domain(paragraph: str) -> str:\n",
        "  prompt = f'Quote: \"{paragraph}\" Domain: '\n",
        "  prompt = prevent_unicode_problems(prompt)\n",
        "  print('THIS IS THE PROMPT:\\n')\n",
        "  # print(semantic_coloring(prompt) + '\\n')\n",
        "  print('NOW THE LLM OUTPUT:')\n",
        "  result = sampler(prompt)\n",
        "  colored_result = semantic_coloring(result)\n",
        "  result = prevent_unicode_problems(result)\n",
        "\n",
        "  # extract the domains\n",
        "  first_line_break = result.find('\\n')\n",
        "  first_line = result[:first_line_break]\n",
        "  domains_list = first_line.split('Domain: ')\n",
        "  if len(domains_list) >= 2:\n",
        "    domains_str = first_line.split('Domain: ')[1]\n",
        "    domains = domains_str.split(', ')\n",
        "  else:\n",
        "    domains = []\n",
        "\n",
        "  return domains, colored_result"
      ],
      "metadata": {
        "id": "86fYf43HtFx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def import_transcript(path: str) -> str:\n",
        "  with open(os.path.join(path), 'r') as f:\n",
        "    text = f.read()\n",
        "  return text"
      ],
      "metadata": {
        "id": "pNI9l0z0J5Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pprint(text: str, color: str | None = None):\n",
        "  if color is not None:\n",
        "    text = colored(text, color)\n",
        "  print(\"\\n\".join(textwrap.wrap(text, width=140)))"
      ],
      "metadata": {
        "id": "GINIjWRIMGAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TEoNsiWlKf41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Transcript paths\n",
        "\n",
        "transcript_paths = [\n",
        "    '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant1_sedentary_Robert_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant10_William_sedentary_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant11_Richard_active_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant11_sedentary_Richard_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant12_active_Johan_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant13_Patricia_active_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant13_Patricia_sedentary_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant14_Thomas_active_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant14_Thomas_sedentary_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant15_active_Fares_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant15_sedentary_Fares_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant16_Mark_sedentary_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant16_active_mark_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant1_active_Robert_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant2_James_active_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant2_sedentary_james_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant3_David_active_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant3_David_sedentary_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant4_Nancy_active_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant4_Nancy_sedentary_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant5_active_Michael_verison3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant5_sedentary_ Michael_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant6_Linda_sedentary_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant7_Mary_sedentary_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant7_active_Mary_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant8_sedentary_john_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant9_Muhammad_active_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant9_sedentary_Muhammad_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant_6_Linda_active_version3.txt',\n",
        "    # '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/participant8_active_John_version3.txt'\n",
        "]"
      ],
      "metadata": {
        "id": "P5EmQLo3CK_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define the process_transcript function\n",
        "\n",
        "def process_transcript(transcript: str):\n",
        "    \"\"\"Process a full transcript. Break it into utterances and analyze each.\n",
        "\n",
        "    Args:\n",
        "      transcript: (string) the text of the transcript.\n",
        "\n",
        "    Returns:\n",
        "      analyses: (list of dicts) each analysis is a dict with fields: paragraph,\n",
        "        the raw quote, domains, the TDF domains, and results, the semantically\n",
        "        colored visualization returned from 'get_domain'.\n",
        "    \"\"\"\n",
        "\n",
        "    analyses = []\n",
        "    # Breaks into utterances on newline characters (consider adding flexibility)\n",
        "    transcript_utterances = transcript.split('\\n')\n",
        "    # Initialize a flag to skip utterances following \"Researcher: \"\n",
        "    skip_next_utterance = False\n",
        "    for utterance in transcript_utterances:\n",
        "        if skip_next_utterance:\n",
        "            skip_next_utterance = False\n",
        "            continue\n",
        "\n",
        "        if utterance.startswith(\"Researcher: \"):\n",
        "            skip_next_utterance = True\n",
        "            continue\n",
        "\n",
        "        # Process only participant utterances here\n",
        "        if utterance.strip():  # Ensures the utterance is not empty\n",
        "            # Assuming get_domain is defined to handle a single utterance and return domains and processed result\n",
        "            domains, result = get_domain(utterance)\n",
        "            analyses.append(dict(paragraph=utterance, domains=domains, result=result))\n",
        "            # Print results - consider replacing with appropriate print logic if pprint is not defined\n",
        "            print(f'Paragraph: {utterance}\\nResult: {result}\\nDomains: {domains}\\n')\n",
        "\n",
        "    return analyses\n",
        "\n"
      ],
      "metadata": {
        "id": "5tU_PqFtZYw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the output of the analysis into a csv file\n",
        "# check the structure of the csv file\n",
        "import csv\n",
        "\n",
        "\n",
        "def save_csv(csv_file_path, analyses):\n",
        "  \"\"\"Load analyses from one transcript and save them in a csv.\"\"\"\n",
        "\n",
        "  # Define the headers for the CSV file\n",
        "  headers = ['paragraph', 'domains', 'result']\n",
        "  # Open the file in write mode ('w') and create a csv.DictWriter object\n",
        "  with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "      writer = csv.DictWriter(file, fieldnames=headers)\n",
        "\n",
        "      # Write the header to the CSV file\n",
        "      writer.writeheader()\n",
        "\n",
        "      # Iterate over each analysis in the analyses list\n",
        "      for analysis in analyses:\n",
        "          # Before writing, convert the list of domains to a string\n",
        "          analysis['domains'] = ', '.join(analysis['domains'])\n",
        "          writer.writerow(analysis)\n",
        "\n",
        "  print(f'Data has been written to {csv_file_path}')\n"
      ],
      "metadata": {
        "id": "kxoNdSY8_lAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing loop"
      ],
      "metadata": {
        "id": "K6E5pqfaFIjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Main processing loop\n",
        "\n",
        "# Specify the path and name of the CSV file you want to create\n",
        "csv_base_file_path = '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/'\n",
        "\n",
        "results_per_transcript = []\n",
        "\n",
        "for idx, path in enumerate(transcript_paths):\n",
        "  print(f'\\n\\n\\nTranscript index: {idx}')\n",
        "  transcript = import_transcript(path=path)\n",
        "  analyses_per_utterance = process_transcript(transcript)\n",
        "  results_per_transcript.append(analyses_per_utterance)\n",
        "  save_path = f'{csv_base_file_path}{idx}.csv'\n",
        "  save_csv(csv_file_path=save_path, analyses=analyses_per_utterance)\n"
      ],
      "metadata": {
        "id": "r5Qm26VKC-ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_per_transcript"
      ],
      "metadata": {
        "id": "gYcXq79TCRZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "WiCmMHu7qH65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7BHSBZvdqS01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7YetAFX2qS6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZlfxG3SXqTB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DOpEsnHHqTGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UdfitQz5qTKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qOqeUL__qIP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WdsycG-wqIUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FaJcMDIFqIYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST EXAMPLE BELOW"
      ],
      "metadata": {
        "id": "-xPg5pQlqT4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test example\n",
        "stop\n",
        "\n",
        "path = '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant1_sedentary_Robert_version3.txt'\n",
        "transcript1 = import_transcript(path)\n",
        "transcript1"
      ],
      "metadata": {
        "id": "2YReL4vrJ5Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test example\n",
        "\n",
        "participant_name = 'Robert'\n",
        "\n",
        "transcript_utterances = transcript1.split('\\n')\n",
        "\n",
        "participant_utterances = []\n",
        "for utterance in transcript_utterances:\n",
        "  if utterance and f'{participant_name}:' in utterance:\n",
        "    participant_utterances.append(utterance)"
      ],
      "metadata": {
        "id": "yX39OscmJ5Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test example\n",
        "\n",
        "analyses = []\n",
        "for utterance in participant_utterances:\n",
        "  pprint(f'Paragraph: {utterance}', color='RED')\n",
        "  domains, result = get_domain(utterance)\n",
        "  analyses.append(dict(paragraph=utterance, result=result))\n",
        "  print(result)\n",
        "\n",
        "  pprint('\\n RESULT:   ' + result, color='BLUE')"
      ],
      "metadata": {
        "id": "wKUDNQkRJ5Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M0L7nN5WJ5Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFC1HaCWJ5hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FEGtdH7-urmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mm7Jv9L21JaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OLD CODE BELOW"
      ],
      "metadata": {
        "id": "XubwJXPkup9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# old stuff below here"
      ],
      "metadata": {
        "id": "Rz2qhMIv1JXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(colored_result)"
      ],
      "metadata": {
        "id": "aj5Vx5B7zO2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(result)"
      ],
      "metadata": {
        "id": "z0KMq9lHps_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "lF1Vrl8_v0cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_without_special_chars = remove_formatting(result)"
      ],
      "metadata": {
        "id": "-wU3DFFqxYwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_without_special_chars"
      ],
      "metadata": {
        "id": "T-ioReBFxsBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_line_break = result_without_special_chars.find('\\n')\n",
        "first_line = result_without_special_chars[:first_line_break]\n",
        "first_line"
      ],
      "metadata": {
        "id": "s4-GkRf8xwTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domains_str = first_line.split('Domain: ')[1]\n",
        "domains = domains_str.split(', ')\n",
        "domains"
      ],
      "metadata": {
        "id": "mGoKOzKix9CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l3CnH0CsyUBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4btBqXRiyT-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZEMtwAnyT8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_without_special_chars)"
      ],
      "metadata": {
        "id": "ZD1igxR0xtC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "3kjisuMwriFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IER-3CKm6wj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A5lq1rtUyaVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aXHKiia6yaTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dCGKWd2OyaQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JSg7S-r_yaN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EaM_b-r6yaFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iOtbrvg0osWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ":"
      ],
      "metadata": {
        "id": "Uo84tEvMC2E1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google drive utilities"
      ],
      "metadata": {
        "id": "vzoJ8MUSUaDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Y0Tamrp8SQix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def import_transcript(path: str) -> str:\n",
        "  with open(os.path.join(path), 'r') as f:\n",
        "    text = f.read()\n",
        "  return text"
      ],
      "metadata": {
        "id": "yx-U0uGkUZTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT-3.0 and 3.5 version"
      ],
      "metadata": {
        "id": "U25R7RLJEYXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pprint(text: str, color: str | None = None):\n",
        "  if color is not None:\n",
        "    text = colored(text, color)\n",
        "  print(\"\\n\".join(textwrap.wrap(text, width=140)))"
      ],
      "metadata": {
        "id": "HpFcJRjd6OxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_coloring(text: str):\n",
        "    indices = text.find('\"')\n",
        "    output = ''\n",
        "    prev_idx = 0\n",
        "    idx = 0\n",
        "    z = 0\n",
        "    while idx >= 0:\n",
        "      color = 'BLUE'\n",
        "      if z % 2 == 0:\n",
        "        color = 'RED'\n",
        "\n",
        "      idx = text.find('\"', prev_idx, -1)\n",
        "      output += colored(text[prev_idx: idx], color=color)\n",
        "\n",
        "      prev_idx = idx + 1\n",
        "      z += 1\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "H8cncBY_2hT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prevent_unicode_problems(text: str) -> str:\n",
        "    return text.encode('ascii', 'namereplace').decode()"
      ],
      "metadata": {
        "id": "bBW3W5Ge28kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_llm_gpt3(prompt: str, max_tokens: int = 256):\n",
        "  \"\"\"Every time we call this function it charges my credit card.\"\"\"\n",
        "  response = openai.Completion.create(\n",
        "    model=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    temperature=0.7,\n",
        "    max_tokens=max_tokens,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "  )\n",
        "  return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "JKl8mWIKeJ2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_llm_gpt35turbo(prompt: str, max_tokens: int = 256):\n",
        "  \"\"\"Every time we call this function it charges my credit card.\"\"\"\n",
        "  response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt }],\n",
        "    temperature=0.7,\n",
        "    max_tokens=max_tokens,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "  )\n",
        "  return response['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "2ojr9Q2SKEHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_llm_gpt3(prompt='hi, how are you?')"
      ],
      "metadata": {
        "id": "0q6y374-NRlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_llm_gpt35turbo(prompt='hi, how are you?')"
      ],
      "metadata": {
        "id": "sdJHI7J0NRi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TDFAssistant:\n",
        "  def __init__(self, model: str = 'gpt3'):\n",
        "    if model=='gpt3':\n",
        "      self.sampler = lambda prompt: sample_llm_gpt3(prompt, max_tokens=256)\n",
        "    elif model=='gpt3.5':\n",
        "      self.sampler = lambda prompt: sample_llm_gpt35turbo(prompt,\n",
        "                                                          max_tokens=256)\n",
        "    else:\n",
        "      raise ValueError(f'Unrecognized model: {model}')\n",
        "\n",
        "    self.instructions = (\n",
        "        'The theoretical domains framework (TDF) is a framework for '\n",
        "        'qualitative analysis. '\n",
        "\n",
        "        'The Theoretical Domains Framework (TDF) \\n '\n",
        "        'was developed by a collaboration of behavioural scientists and \\n'\n",
        "        'implementation researchers who identified theories relevant to \\n'\n",
        "        'implementation and grouped constructs from \\n'\n",
        "        'these theories into domains. \\n'\n",
        "        'The collaboration aimed to provide a comprehensive, \\n'\n",
        "        'theory-informed approach to identify determinants of behaviour.\\n'\n",
        "        #'A domain is'\n",
        "        #'Explain barriers and enablers'\n",
        "\n",
        "        'You are a health psychologist who specialises \\n'\n",
        "        'in qualitative research methods. \\n'\n",
        "        'As your main day-to-day job, '\n",
        "        'you annotate paragraphs of transcribed verbatim interviews. \\n'\n",
        "        'You line-by-line annotate quotes within each paragraph using TDF. \\n'\n",
        "        'This involves reading the paragraph and categorizing the quotes into \\n'\n",
        "        '14 TDF domains. '\n",
        "        'The 14 domains are '\n",
        "        '1) Knowledge; '\n",
        "        '2) Skills; '\n",
        "        '3) Social/professional role and identity; '\n",
        "        '4) Beliefs about capabilities; '\n",
        "        '5) Optimism; '\n",
        "        '6) Beliefs about consequences; '\n",
        "        '7) Reinforcement; '\n",
        "        '8) Intentions; '\n",
        "        '9) Goals; '\n",
        "        '10) Memory, attention, and decision processes; '\n",
        "        '11) Environment context and resources; '\n",
        "        '12) Social influences; '\n",
        "        '13) Emotion; '\n",
        "        '14) Behavioral regulation.\\n'\n",
        "        'It is OK if there is more than one domain in one paragraph.\\n'\n",
        "        'Show your work. Print the text from the paragraph (i.e., quote) \\n'\n",
        "        'that you used to identify each domain. \\n'\n",
        "        'For each identified domain, '\n",
        "        'include the quote from the paragraph that \\n'\n",
        "        'maps onto the domain. '\n",
        "        'Always print the exact quote from the paragraph and encapsulate it in quotation marks. '\n",
        "        'At the end, print out a table summarising the explanation only, '\n",
        "        'where the first column is the domain name and '\n",
        "        'the second column is the quote '\n",
        "        'group the table by domains in the following order: '\n",
        "        '1) Knowledge; '\n",
        "        '2) Skills; '\n",
        "        '3) Social/professional role and identity; '\n",
        "        '4) Beliefs about capabilities; '\n",
        "        '5) Optimism; '\n",
        "        '6) Beliefs about consequences; '\n",
        "        '7) Reinforcement; '\n",
        "        '8) Intentions; '\n",
        "        '9) Goals; '\n",
        "        '10) Memory, attention, and decision processes; '\n",
        "        '11) Environment context and resources; '\n",
        "        '12) Social influences; '\n",
        "        '13) Emotion; '\n",
        "        '14) Behavioral regulation. '\n",
        "        'add a third column counting the number of quotes for each domain '\n",
        "        'Here are some examples of how to apply TDF to \\n'\n",
        "        'extract the domains from a paragraph about barriers and enablers \\n'\n",
        "        'influencing health professional\\'s behaviour, such as implementation of \\n'\n",
        "        'best practices and medical guidelines: \\n'\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    examples = []\n",
        "\n",
        "     # 1) Knowledge\n",
        "    examples.append((\n",
        "        'Quote: \"you educate the patients on you know, '\n",
        "        'safety awareness between hot cold \\n'\n",
        "        'and sharp objects and what not, '\n",
        "        'but in terms of rehabilitation...I\\'m just not aware of what to do.\"\\n'\n",
        "        'Domain: \"Knowledge\" '\n",
        "    ))\n",
        "\n",
        "      # 2) Skills\n",
        "    examples.append((\n",
        "        'Quote: \"I think a lot of it is to do with the training, '\n",
        "        'I was talking to a few junior doctors in respiratory \\n'\n",
        "        'and a lot of them haven\\'t even heard about the training '\n",
        "        'package on the website, but they’re putting tubes down.\" \\n'\n",
        "        'Domain: \"Skills\" '\n",
        "    ))\n",
        "\n",
        "      # 3) Social/professional role and identity\n",
        "    examples.append((\n",
        "       'Quote:\"A sense that I was not a medical professional, '\n",
        "       'and this might be out of my realm of service.\" '\n",
        "       'Domain: \"Social/professional role and identity\" '\n",
        "    ))\n",
        "\n",
        "      # 4) Beliefs about capabilities\n",
        "    examples.append((\n",
        "        'Quote: \"I think there might also be an issue with confidence.\" '\n",
        "        'Domain: \"Beliefs about capabilities\" '\n",
        "    ))\n",
        "\n",
        "      # 5) Optimism\n",
        "    examples.append((\n",
        "        'Quote: \"I feel a mix of excitement and scepticism, to be honest.\" '\n",
        "        'Domain: \"Optimism\" '\n",
        "   ))\n",
        "\n",
        "      # 6) Beliefs about consequences\n",
        "    examples.append((\n",
        "        'Quote: \"Because my credibility, you know,if I start saying, '\n",
        "        'you know, smoking increases your risk of lung cancer \\n'\n",
        "        'or doing this does that, '\n",
        "        'and I’m standing there as a skin cancer specialist nurse, \\n'\n",
        "        'I think that you, it all just turns into a bit of a blah blah blah\" \\n'\n",
        "        'Domain: \"Beliefs about consequences\" '\n",
        "   ))\n",
        "\n",
        "\n",
        "      # 7) Reinforcement\n",
        "    examples.append((\n",
        "        'Quote: \"I think everyone\\’s very happy to do things '\n",
        "        'if they feel the patient is going to get a better outcome from it, '\n",
        "        'and I think that’s one of the biggest drivers for our inpatient\" '\n",
        "        'Domain: \"Reinforcement\" '\n",
        "   ))\n",
        "\n",
        "      # 8) Intentions\n",
        "    examples.append((\n",
        "        'Quote: \"I\\’m keen to apply it more broadly I guess,'\n",
        "        'across the board rather than just the ones that are really severe.\" '\n",
        "        'Domain: \"Intentions\" '\n",
        "   ))\n",
        "\n",
        "\n",
        "      # 9) Goals\n",
        "    examples.append((\n",
        "        'Quote: \"there\\’s so many other things we need to look at like home '\n",
        "        'assess and other functions and mobility, so yeah, '\n",
        "        'it’s a bit low on the priority list\" '\n",
        "        'Domain: \"Goals\" '\n",
        "   ))\n",
        "\n",
        "      # 10) Memory, attention, and decision processes\n",
        "    examples.append((\n",
        "        'Quote: \"\"When you\\re doing risk assessments, '\n",
        "      'just those few seconds away where you\\'re '\n",
        "      'looking at the computer or typing, you miss '\n",
        "      'moments with the patient where they might open up '\n",
        "      'or you just miss the odd little slip in their body '\n",
        "      'language that might help you.\" '\n",
        "        'Domain: \"Memory, attention, and decision processes\" '\n",
        "   ))\n",
        "\n",
        "      # 11) Environment context and resources\n",
        "    examples.append((\n",
        "        'Quote: \"I think time constraints from an inpatientpoint of view because '\n",
        "        'every one is so stretched, and I think '\n",
        "        'even with some of my [musculoskeletal] colleagues \\n'\n",
        "        'they feel that they have to just treat what\\'s in front of them '\n",
        "        'in the time that they have.\" \\n'\n",
        "        'Domain: \"Environmental contextand resources\"'\n",
        "    ))\n",
        "\n",
        "      # 12) Social influences\n",
        "    examples.append((\n",
        "        'Quote: \"If my boss told me to do one it would \\n'\n",
        "        'be very difficult for me to, '\n",
        "        'depending on which the boss was, generally you\\'d be like no \\n'\n",
        "        'but don\\'t you know that local guidelines are…they’d be like '\n",
        "        'I said get a chest x-ray, you\\'d be like oh alright.\" \\n'\n",
        "        'Domain: \"Social influences\"'\n",
        "    ))\n",
        "      # 13) Emotion\n",
        "    examples.append((\n",
        "        'Quote: \"I think the nurses are still quite anxious because it\\'s so big '\n",
        "        'even now I think they\\'re still anxious about pH and they just want to \\n'\n",
        "        'know that it\\'s in the right place.\" \\n'\n",
        "        'Domain: \"Emotion\" '\n",
        "    ))\n",
        "      # 14) Behavioral regulation.\n",
        "    examples.append((\n",
        "        'Quote: \"I did some reading upon this immediately and \\n'\n",
        "        'then in grained in my mind what were '\n",
        "        'the exact differences I was doing some reading up and \\n'\n",
        "        'became aware of the study,becauseI felt that was a gap in my knowledge. \\n'\n",
        "        'Obviously, I was offering all the antenatal screening, apart from the \\n'\n",
        "        'genetic carrier screening which is now something that I do \\n'\n",
        "        'mention to couples.\" \\n'\n",
        "        'Domain: \"Behaviour regulation\" '\n",
        "    ))\n",
        "\n",
        "\n",
        "\n",
        "    examples.append((\n",
        "        'Quote: \"The main barriers I face in being physically active are '\n",
        "        'my health conditions, '\n",
        "        'including heart failure, aortic stenosis, pulmonary hypertension, diabetes, '\n",
        "        'and rheumatoid arthritis. These conditions limit my physical abilities and  '\n",
        "        'energy levels and make it difficult for me to do more physical activity./n '\n",
        "        'Additionally, living in a rural area with limited infrastructure '\n",
        "        'and options for physical activity can be a barrier as well. '\n",
        "        'Other barriers include my sedentary lifestyle, '\n",
        "        'which can make it hard to break the habit of being inactive, '\n",
        "        'and external factors such as weather, '\n",
        "        'which can make it difficult to go outside and be active. '\n",
        "        'My schedule and other commitments can also be a barrier, '\n",
        "        'making it hard to find the time to be active. '\n",
        "        'On the other hand, enablers that help me '\n",
        "        'to be more physically active include setting small, '\n",
        "        'achievable goals for myself, finding activities that I enjoy, '\n",
        "        'having a companion to exercise with, '\n",
        "        'and listening to my body and being mindful of my health conditions. '\n",
        "        'My home environment also can help as it is equipped with safety features '\n",
        "        'that make it easier for me to move around. '\n",
        "        'The advice and guidelines from my healthcare providers '\n",
        "        'also help me to stay active in a safe way. '\n",
        "\n",
        "        'Domain: \"Beliefs about capabilities\", '\n",
        "        '\"Environmental context and resources\", '\n",
        "        '\"Goals\", '\n",
        "        '\"Behavioural regulation\", '\n",
        "        '\"Social influences\", '\n",
        "\n",
        "        'Explanation:'\n",
        "        '\"Beliefs about capabilities\" is noted because of the following quote: '\n",
        "        '\"The main barriers I face in '\n",
        "        'being physically active are my health conditions, '\n",
        "        'including heart failure, '\n",
        "        'aortic stenosis, pulmonary hypertension, diabetes, '\n",
        "        'and rheumatoid arthritis. '\n",
        "        'These conditions limit my physical abilities and '\n",
        "        'energy levels and make it difficult for me to do more '\n",
        "        'physical activity.\"/n '\n",
        "        '\"Environmental context and resources\" '\n",
        "        'is noted because of the following quote: '\n",
        "        '\"Additionally, living in a rural area with limited infrastructure '\n",
        "        'and options for physical activity can be a barrier as well./n '\n",
        "        '\"Environmental context and resources\" '\n",
        "        'is noted because of the following quote: '\n",
        "        '\"and external factors such as weather, which can make it '\n",
        "        'difficult to go outside and be active.\" /n'\n",
        "        '\"Goals\" is noted because of the following quote: '\n",
        "        '\"On the other hand, enablers that help me to be more physically '\n",
        "        'active include setting small, achievable goals for myself,\" /n'\n",
        "        '\"Behavioural regulation\" '\n",
        "        'is noted because of the following quote: '\n",
        "        '\"finding activities that I enjoy,\" /n'\n",
        "        '\"Social influences\" '\n",
        "        'is noted because of the following quote: '\n",
        "        '\"having a companion to exercise with,\" '\n",
        "        '\"Environmental context and resources\" '\n",
        "        'is noted because of the following quote: '\n",
        "        '\"My home environment also can help as '\n",
        "        'it is equipped with safety features '\n",
        "        'that make it easier for me to move around.\" /n'\n",
        "        '\"Social influences\" '\n",
        "        'is noted because of the following quote: '\n",
        "        '\"The advice and guidelines from my healthcare providers '\n",
        "        'also help me to stay active in a safe way.\" /n'\n",
        "    ))\n",
        "\n",
        "    examples = '\\n'.join(examples)\n",
        "    self.preamble = f'{self.instructions}\\n{examples}'\n",
        "\n",
        "  def get_domain(self, paragraph: str, verbose=True) -> str:\n",
        "    prompt = f'{self.preamble} Quote: \"{paragraph}\" Domain: '\n",
        "    prompt = prevent_unicode_problems(prompt)\n",
        "    if verbose:\n",
        "      print('THIS IS THE PROMPT:\\n')\n",
        "      print(semantic_coloring(prompt) + '\\n')\n",
        "      print('NOW THE LLM OUTPUT:')\n",
        "    result = self.sampler(prompt)\n",
        "    result = semantic_coloring(result)\n",
        "    result = prevent_unicode_problems(result)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "A9sZrhJl6OtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xl7R9ydLVEuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tdf_assistant = TDFAssistant(model='gpt3')\n",
        "tdf_assistant = TDFAssistant(model='gpt3.5')\n",
        "\n",
        "paragraph = (\n",
        "    '\"My physical activity level may be somewhat limited compared '\n",
        "    'to people my age without chronic health conditions like mine. '\n",
        "    'However, I believe that I am still able to engage in enough physical activity '\n",
        "    'maintain my overall well-being. '\n",
        "    'I try to stay active within my limits and listen to my body. '\n",
        "    'I also keep in mind the recommendations and restrictions '\n",
        "    'given by my doctor when it comes to physical activity. '\n",
        "    'I know that my situation is unique and I cannot compare my activity level '\n",
        "    'to others my age who don\\'t have my same chronic illnesses and limitations. '\n",
        "    'But I try to make the most of what I can do, and try to focus on the benefits '\n",
        "    'for my health rather than what I can\\'t do.\"'\n",
        " )\n",
        "\n",
        "pprint(tdf_assistant.get_domain(paragraph), color='BLUE')"
      ],
      "metadata": {
        "id": "HVN4rmU76P4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zz9b6tTy-Cvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/priors_from_machines/early_explorations/piloting_version3/txt/Participant1_sedentary_Robert_version3.txt'\n",
        "transcript = import_transcript(path)\n",
        "transcript"
      ],
      "metadata": {
        "id": "JLGp77RsUlnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "participant_name = 'Robert'\n",
        "\n",
        "transcript_utterances = transcript.split('\\n')\n",
        "\n",
        "participant_utterances = []\n",
        "for utterance in transcript_utterances:\n",
        "  if utterance and f'{participant_name}:' in utterance:\n",
        "    participant_utterances.append(utterance)"
      ],
      "metadata": {
        "id": "itaBQPMgVuIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyses = []\n",
        "for utterance in participant_utterances:\n",
        "  pprint(f'Paragraph: {utterance}', color='RED')\n",
        "  result = tdf_assistant.get_domain(utterance, verbose=False)\n",
        "  analyses.append(dict(paragraph=utterance, result=result))\n",
        "  pprint('\\n RESULT:   ' + result, color='BLUE')"
      ],
      "metadata": {
        "id": "jjkdzYekW0vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, analysis in enumerate(analyses):\n",
        "  print(f'\\n{idx}: ')\n",
        "  print('  paragraph: ' + analysis['paragraph'])\n",
        "  print('  analysis: ' + analysis['result'])"
      ],
      "metadata": {
        "id": "zaF-4W4HT8XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(analyses)\n",
        "df"
      ],
      "metadata": {
        "id": "A8W6tK54TUEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OGa1fSxn-1wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "k-k_-ltGaZRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "class TDFQuoteOrganizer:\n",
        "    def __init__(self, analyses):\n",
        "        self.analyses = analyses\n",
        "        self.df = self._create_dataframe()\n",
        "\n",
        "    def _create_dataframe(self):\n",
        "        # Extract domain and quote from analyses\n",
        "        data = [(analysis['result'], analysis['paragraph']) for analysis in self.analyses]\n",
        "        # Create DataFrame\n",
        "        df = pd.DataFrame(data, columns=['Domain', 'Quote'])\n",
        "        return df\n",
        "\n",
        "    def group_and_order(self):\n",
        "        # Group by 'Domain' and join all quotes in 'Quote' column\n",
        "        df_grouped = self.df.groupby('Domain')['Quote'].apply(', '.join).reset_index()\n",
        "        # Order by 'Domain'\n",
        "        df_ordered = df_grouped.sort_values('Domain')\n",
        "        return df_ordered\n"
      ],
      "metadata": {
        "id": "du0M1z9WdgN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the organizer with the analyses\n",
        "organizer = TDFQuoteOrganizer(analyses)\n",
        "\n",
        "# Group and order the quotes\n",
        "df_ordered = organizer.group_and_order()\n",
        "\n",
        "# Show the DataFrame\n",
        "print(df_ordered)\n",
        "\n",
        "df_ordered = pd.DataFrame(df_ordered)\n"
      ],
      "metadata": {
        "id": "c2D4D64qdjtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Opv3y0fNj2TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ordered"
      ],
      "metadata": {
        "id": "6AFLOlcThP-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_ordered)"
      ],
      "metadata": {
        "id": "uDWhztydkg-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUCULTQEj3td"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}